{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6936030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 14:06:13.994354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-12 14:06:13.994399: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from numpy import array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from statistics import mean as mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8bd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed (3968)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7baa74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv (\"http://raptor.kent.ac.uk/~ds756/Data/iris.csv\")\n",
    "Species = iris.Species.unique ()\n",
    "Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8f261",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">_____________________________________________________________________________________</p>\n",
    "<p style=\"font-size:20px\">Build a classifier for the iris dataset.</p>\n",
    "<p style=\"font-size:20px\">The first step, construct the training data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e151e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.1316282072803005e-16\n",
      "-2.3684757858670006e-16\n",
      "-2.3684757858670006e-16\n",
      "-1.4210854715202004e-16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal_Length</th>\n",
       "      <th>Sepal_Width</th>\n",
       "      <th>Petal_Length</th>\n",
       "      <th>Petal_Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-2.131628e-16</td>\n",
       "      <td>-2.368476e-16</td>\n",
       "      <td>-2.368476e-16</td>\n",
       "      <td>-1.421085e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.026253e-01</td>\n",
       "      <td>3.246273e-01</td>\n",
       "      <td>5.618390e-01</td>\n",
       "      <td>5.860361e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.504052e-01</td>\n",
       "      <td>-7.874876e-01</td>\n",
       "      <td>-8.777849e-01</td>\n",
       "      <td>-8.452076e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.614263e-01</td>\n",
       "      <td>-1.916584e-01</td>\n",
       "      <td>-6.868237e-01</td>\n",
       "      <td>-6.914403e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.106969e-02</td>\n",
       "      <td>-4.270109e-02</td>\n",
       "      <td>1.884150e-01</td>\n",
       "      <td>7.739621e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.706645e-01</td>\n",
       "      <td>1.807349e-01</td>\n",
       "      <td>4.271165e-01</td>\n",
       "      <td>4.618145e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sepal_Length   Sepal_Width  Petal_Length   Petal_Width\n",
       "count  1.500000e+02  1.500000e+02  1.500000e+02  1.500000e+02\n",
       "mean  -2.131628e-16 -2.368476e-16 -2.368476e-16 -1.421085e-16\n",
       "std    4.026253e-01  3.246273e-01  5.618390e-01  5.860361e-01\n",
       "min   -7.504052e-01 -7.874876e-01 -8.777849e-01 -8.452076e-01\n",
       "25%   -3.614263e-01 -1.916584e-01 -6.868237e-01 -6.914403e-01\n",
       "50%   -2.106969e-02 -4.270109e-02  1.884150e-01  7.739621e-02\n",
       "75%    2.706645e-01  1.807349e-01  4.271165e-01  4.618145e-01\n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-process our continuous features.\n",
    "#  1. Scale\n",
    "#  2. Translate\n",
    "\n",
    "data = iris\n",
    "data = data.drop (columns = \"Mono\")\n",
    "\n",
    "for u in data:\n",
    "    if is_numeric_dtype (data[u]):\n",
    "        data[u] -= data[u].mean ()            # -1 ≤ x ≤ 1, mean (data[u]) == 0.0\n",
    "        data[u] /= data[u].max ()             # 0 ≤ x ≤ 1\n",
    "        print (data[u].mean ())\n",
    "\n",
    "data.describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ae99a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the values from the dataframe into an array\n",
    "dataset = data.values\n",
    "\n",
    "# Split off our input features\n",
    "x = dataset[:, 0:4].astype(float)\n",
    "\n",
    "# Split off our species\n",
    "Labels = dataset [:, 4] \n",
    "Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d04a97",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">_____________________________________________________________________________________</p>\n",
    "\n",
    "<p style=\"font-size:20px\">Hot-encode our species.  This is done as follows:</p>\n",
    "\n",
    "<ul style=\"font-size:20px\">\n",
    "    <li>Discover all of the unique labels and assign them a unique integers.</li>  \n",
    "    <li>The integers corrospond to indices in the hot-encoded vector.</li>\n",
    "    <li>Build a vector of integers corrosponding to their labels.</li>\n",
    "    <li>Request Keras to build our ANN.</li>\n",
    "    <li>Build an array of vectors where only the correct entry has a 1.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25379014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Hot = LabelEncoder ()\n",
    "\n",
    "# 1. Find the unique labels and assign indices\n",
    "Hot.fit (Labels)                      \n",
    "\n",
    "# 2. Build a vector of indices\n",
    "HotLabels = Hot.transform (Labels)    \n",
    "\n",
    "# Finally, build the vectors (3)\n",
    "TrainingLabels = np_utils.to_categorical (HotLabels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05463b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HotLabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75e85ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26902d4",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">_____________________________________________________________________________________</p>\n",
    "<p style=\"font-size:20px\">We have prepared our data, now specify the ANN</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e86ea2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 14:06:15.672550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-12 14:06:15.672620: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-12 14:06:15.672645: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter): /proc/driver/nvidia/version does not exist\n",
      "2022-12-12 14:06:15.672879: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Keras container for our model\n",
    "model = Sequential()                                                 \n",
    "\n",
    "# input vector of dim 4, for our 4 predictors\n",
    "model.add (Dense (8, input_dim=4, activation='sigmoid'))    \n",
    "\n",
    "# Second layer, 8 neurons\n",
    "model.add (Dense(8, activation='relu'))                              \n",
    "\n",
    "# Softmax layer for classification\n",
    "model.add (Dense (3, activation='softmax'))                          \n",
    "\n",
    "# Having specified the topology we now build the ANN\n",
    "model.compile (loss='categorical_crossentropy', optimizer='adam')    \n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe8d44",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">_____________________________________________________________________________________</p>\n",
    "<p style=\"font-size:20px\">We have our training data, and our ANN, we can train the ANN now.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0401d66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.57672643661499"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time ()\n",
    "\n",
    "h = model.fit (x, TrainingLabels, verbose=False, epochs = 5000)\n",
    "\n",
    "dt = time.time () - start_time\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d53a531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def LossHistory (history):\n",
    "  plt.plot (history.history['loss'], label='Loss')\n",
    "  plt.xlabel ('Epoch')\n",
    "  plt.ylabel ('Loss')\n",
    "  plt.legend ()\n",
    "  plt.grid (True)\n",
    "  plt.show ()\n",
    "\n",
    "LossHistory (h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef6fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = array([x[111, ]])  # How did we do?  Let's try one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69e2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Softmax\n",
    "\n",
    "def Inference (x):\n",
    "    p0 = list (model.predict (query)[0])\n",
    "    return Species[p0.index (max (p0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a7d4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Inference (query) == iris.Species[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad2b823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 virginica versicolor\n",
      "133 versicolor virginica\n"
     ]
    }
   ],
   "source": [
    "for i in range (0, 150):\n",
    "    query = array ([x[i, ]])\n",
    "    if Inference (query) != iris.Species[i]:\n",
    "        print (i, Inference (query), iris.Species[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
